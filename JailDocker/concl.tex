\section{Conclusion and Future Works}

%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
%Paragraph 1:Spark Scalability의 연구에 대한 설명
%$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$
\ifkor
We propose a docker container-based partitioning method for Apache
Spark scalability on scale-up server.
To eliminate GC and NUMA effect, we divide per-socket and best-fit partitioning
using the docker container.
Evaluation results using the wordcount, navi-basian, grep and k-means reveal
that our method better performance up to 1.5 times compared to existing
solutions.
\newline\\
\noindent
\textbf{Future Directions.} 
To achieve our goal, this paper only focused on the manual docker
container-based partitioning, and our future directions are:
\begin{itemize}
\item \textbf{Solving the straggler tasks problem.} straggler tasks
significantly extend job completion times.
To mitigate this problem, we may use dynamic resource allocation solution in
dockers to maximized cpu utilization for the straggler tasks by using our new
resource hand-over solution.
\item \textbf{Auto-tuned partitioning.} In this paper, only support manualy
partition using docker container. However, many of sicent or big data acaldld
may reuse similar workload, so training phase for finding the best-fit
partitioning can be superior solution than manually partition similar way of
compiler-based auto-tuner[].

\end{itemize}

\else

\fi
